{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-3:\n",
    "# Exercise 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importing necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "sb.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age Title  \\\n",
       "0           0          767   33   NaN   \n",
       "1           1         1080   34   NaN   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "\n",
       "   Positive Feedback Count Division Name Department Name Class Name  \n",
       "0                        0     Initmates        Intimate  Intimates  \n",
       "1                        4       General         Dresses    Dresses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Womens Clothing E-Commerce Reviews.csv\\Womens Clothing E-Commerce Reviews.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-1:</br>  Preprocessing: </br> &emsp; a.  Find any null values are present or not, If present remove those data. </br> &emsp; b.  Remove the data that have less than 5 reviews. </br> &emsp; c.  Clean the data and remove the special characters and replace the contractions with its &emsp; expansion. Convert the uppercase character to lower case. Also, remove the punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               23486 non-null  int64 \n",
      " 1   Clothing ID              23486 non-null  int64 \n",
      " 2   Age                      23486 non-null  int64 \n",
      " 3   Title                    19676 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   23486 non-null  int64 \n",
      " 6   Recommended IND          23486 non-null  int64 \n",
      " 7   Positive Feedback Count  23486 non-null  int64 \n",
      " 8   Division Name            23472 non-null  object\n",
      " 9   Department Name          23472 non-null  object\n",
      " 10  Class Name               23472 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(columns=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "Clothing ID                   0\n",
       "Age                           0\n",
       "Title                      3810\n",
       "Review Text                 845\n",
       "Rating                        0\n",
       "Recommended IND               0\n",
       "Positive Feedback Count       0\n",
       "Division Name                14\n",
       "Department Name              14\n",
       "Class Name                   14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19662, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 0\n",
       "Clothing ID                0\n",
       "Age                        0\n",
       "Title                      0\n",
       "Review Text                0\n",
       "Rating                     0\n",
       "Recommended IND            0\n",
       "Positive Feedback Count    0\n",
       "Division Name              0\n",
       "Department Name            0\n",
       "Class Name                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18401, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Rating'] = 0\n",
    "\n",
    "for cloth in data['Clothing ID'].unique():\n",
    "    data.loc[data['Clothing ID']==cloth, 'Rating'] = data['Clothing ID'].value_counts()[cloth]\n",
    "    \n",
    "data = data[data.Rating>=5]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Text for contractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"a'ight\":\"alright\",\n",
    "\"ain't\":\"are not\",\n",
    "\"amn't\":\"am not\",\n",
    "\"aren't\":\"are not\",\n",
    "\"can't\":\"cannot\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\":\"could have\",\n",
    "\"couldn't\":\"could not\",\n",
    "\"couldn't've\":\"could not have\",\n",
    "\"daren't\":\"dare not\",\n",
    "\"daresn't\":\"dare not\",\n",
    "\"dasn't\":\"dare not\",\n",
    "\"didn't\":\"did not\",\n",
    "\"doesn't\":\"does not\",\n",
    "\"don't\":\"do not\",\n",
    "\"everybody's\":\"everybody is\",\n",
    "\"everyone's\":\"everyone is\",\n",
    "\"giv'n\":\"given\",\n",
    "\"gonna\":\"going to\",\n",
    "\"gon't\":\"go not\", \n",
    "\"gotta\":\"got to\",\n",
    "\"hadn't\":\"had not\",\n",
    "\"had've\":\"had have\",\n",
    "\"hasn't\":\"has not\",\n",
    "\"haven't\":\"have not\",\n",
    "\"he'd\":\"he had\", \n",
    "\"he'll\":\"he will\",\n",
    "\"he's\":\"he is\",\n",
    "\"here's\":\"here is\",\n",
    "\"how'd\":\"how did\",\n",
    "\"how'll\":\"how will\",\n",
    "\"how're\":\"how are\",\n",
    "\"how's\":\"how is\",\n",
    "\"I'd\":\"I had\",\n",
    "\"I'd've\":\"I would have\",\n",
    "\"I'd'nt\":\"I would not\",\n",
    "\"I'd'nt've\":\"I would not have\",\n",
    "\"I'll\":\"I will\",\n",
    "\"I'm\":\"I am\",\n",
    "\"I've\":\"I have\",\n",
    "\"isn't\":\"is not\",\n",
    "\"it'd\":\"it would\",\n",
    "\"it'll\":\"it will\",\n",
    "\"it's\":\"it is\",\n",
    "\"let's\":\"let us\",\n",
    "\"ma'am\":\"madam\",\n",
    "\"mayn't\":\"may not\",\n",
    "\"may've\":\"may have\",\n",
    "\"mightn't\":\"might not\",\n",
    "\"might've\":\"might have\",\n",
    "\"mustn't\":\"must not\",\n",
    "\"mustn't've\":\"must not have\",\n",
    "\"must've\":\"must have\",\n",
    "\"needn't\":\"need not\",\n",
    "\"needn't've\":\"need not have\",\n",
    "\"o'clock\":\"of the clock\",\n",
    "\"oughtn't\":\"ought not\",\n",
    "\"oughtn't've\":\"ought not have\",\n",
    "\"shan't\":\"shall not\",\n",
    "\"she'd\":\"she would\",\n",
    "\"she'll\":\"she will\",\n",
    "\"she's\":\"she is\",\n",
    "\"should've\":\"should have\",\n",
    "\"shouldn't\":\"should not\",\n",
    "\"shouldn't've\":\"should not have\",\n",
    "\"somebody's\":\"somebody is\",\n",
    "\"someone's\":\"someone is\",\n",
    "\"something's\":\"something is\",\n",
    "\"so're\":\"so are\",\n",
    "\"so’s\":\"so is\",\n",
    "\"so’ve\":\"so have\",\n",
    "\"that'll\":\"that will\",\n",
    "\"that're\":\"that are\",\n",
    "\"that's\":\"that is\",\n",
    "\"that'd\":\"that would\",\n",
    "\"there'd\":\"there would\",\n",
    "\"there'll\":\"there will\",\n",
    "\"there're\":\"there are\",\n",
    "\"there's\":\"there is\",\n",
    "\"these're\":\"these are\",\n",
    "\"these've\":\"these have\",\n",
    "\"they'd\":\"they would\",\n",
    "\"they'll\":\"they will\",\n",
    "\"they're\":\"they are\",\n",
    "\"they've\":\"they have\",\n",
    "\"this's\":\"this is\",\n",
    "\"those're\":\"those are\",\n",
    "\"those've\":\"those have\",\n",
    "\"to've\":\"to have\",\n",
    "\"wasn't\":\"was not\",\n",
    "\"we'd\":\"we would\",\n",
    "\"we'd've\":\"we would have\",\n",
    "\"we'll\":\"we will\",\n",
    "\"we're\":\"we are\",\n",
    "\"we've\":\"we have\",\n",
    "\"weren't\":\"were not\",\n",
    "\"what'd\":\"what did\",\n",
    "\"what'll\":\"what will\",\n",
    "\"what're\":\"what are\",\n",
    "\"what's\":\"what is\",\n",
    "\"what've\":\"what have\",\n",
    "\"when's\":\"when is\",\n",
    "\"where'd\":\"where did\",\n",
    "\"where'll\":\"where will\",\n",
    "\"where're\":\"where are\",\n",
    "\"where's\":\"where is\",\n",
    "\"where've\":\"where have\",\n",
    "\"which'd\":\"which would\",\n",
    "\"which'll\":\"which will\",\n",
    "\"which're\":\"which are\",\n",
    "\"which's\":\"which is\",\n",
    "\"which've\":\"which have\",\n",
    "\"who'd\":\"who would\",\n",
    "\"who'd've\":\"who would have\",\n",
    "\"who'll\":\"who will\",\n",
    "\"who're\":\"who are\",\n",
    "\"who's\":\"who is\",\n",
    "\"who've\":\"who have\",\n",
    "\"why'd\":\"why did\",\n",
    "\"why're\":\"why are\",\n",
    "\"why's\":\"why is\",\n",
    "\"won't\":\"will not\",\n",
    "\"would've\":\"would have\",\n",
    "\"wouldn't\":\"would not\",\n",
    "\"wouldn't've\":\"would not have\",\n",
    "\"y'at\":\"you at\",\n",
    "\"yes’m\":\"yes madam\",\n",
    "\"you'd\":\"you would\",\n",
    "\"you'll\":\"you will\",\n",
    "\"you're\":\"you are\",\n",
    "\"you've\":\"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Function for converting contractions to expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        x = x.replace('\\\\','')\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Functions Upper to Lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_to_lower(x):\n",
    "    if type(x) is str:\n",
    "        return x.lower()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Functions to remove punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    if type(text) is str:\n",
    "        for p in string.punctuation:\n",
    "            text = text.replace(p, '')\n",
    "        return text\n",
    "    else:\n",
    "        return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Function Remove Special Characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    special_chars = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    if type(text) is str:\n",
    "        for p in special_chars:\n",
    "            text = text.replace(p, '')\n",
    "        return text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text'] = data['Review Text'].apply(lambda x:cont_to_exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text'] = data['Review Text'].apply(lambda x:upper_to_lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text'] = data['Review Text'].apply(lambda x:remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text'] = data['Review Text'].apply(lambda x:remove_special_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity_review'] = data['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-2: Separate the columns into dependent and independent variables (or features and labels). Then you split those variables into train and test sets (80:20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 0', 'Clothing ID', 'Review Text', 'Title', 'Department Name', 'Division Name', 'Class Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['Recommended IND'])\n",
    "y = data['Recommended IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=105)\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [cname for cname in x.columns if x[cname].dtype == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-3: Apply the Naïve Bayes Classification Algorithm on Sentiment category to predict if item is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps = [\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=10)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                              ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "proba = pipe.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question-4: Tabulate accuracy in terms of precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.09      0.15       680\n",
      "           1       0.83      0.97      0.89      3001\n",
      "\n",
      "    accuracy                           0.81      3681\n",
      "   macro avg       0.62      0.53      0.52      3681\n",
      "weighted avg       0.75      0.81      0.76      3681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
